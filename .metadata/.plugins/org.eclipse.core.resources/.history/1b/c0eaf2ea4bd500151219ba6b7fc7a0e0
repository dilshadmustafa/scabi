/**
 * @author Dilshad Mustafa
 * (c) Dilshad Mustafa
 * All Rights Reserved.
 * @version 1.0
 * @since 11-Feb-2016
 * File Name : DBackFile.java
 */
package com.dilmus.scabi.common;

import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.text.DateFormat;
import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.Date;
import java.util.Set;
import java.util.TimeZone;

import org.bson.Document;
import org.bson.types.ObjectId;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.mongodb.BasicDBObject;
import com.mongodb.DBCollection;
import com.mongodb.client.MongoDatabase;
import com.mongodb.client.gridfs.GridFSBucket;
import com.mongodb.client.gridfs.GridFSBuckets;
import com.mongodb.client.gridfs.GridFSDownloadStream;
import com.mongodb.client.gridfs.GridFSUploadStream;
import com.mongodb.client.gridfs.model.GridFSDownloadByNameOptions;
import com.mongodb.client.gridfs.model.GridFSUploadOptions;

import java.time.*;
/**
 * @author Dilshad Mustafa
 *
 */
public class DBackFile {

	final static Logger log = LoggerFactory.getLogger(DBackTable.class);

	private DBackDB m_ddb = null;
	private MongoDatabase m_mongodb = null;
    private GridFSBucket m_gridFSBucket = null;
    private GridFSUploadOptions m_options = null;
    private boolean m_firstTime = true;
	private int m_chunkSize = 0; // Bytes
	private int m_bufferSize = 0; // Bytes
    
	public DBackFile(DBackDB ddb) {
		m_ddb = ddb;
		m_mongodb = ddb.getDatabase();
		m_firstTime = true;
		m_chunkSize = 1024*1024;
		m_bufferSize = 64*1024*1024;

	}
	
	public int setBufferSize(int bufferSize) {
		m_bufferSize = bufferSize;
		return 0;
	}
	
	public int updateMetaData(ObjectId fileID) throws IOException, DScabiException {
		BasicDBObject documentWhere = new BasicDBObject();
		BasicDBObject documentUpdate = new BasicDBObject();
		
    	documentWhere.put("_id", fileID);
    	documentUpdate.put("PutStatus", "Completed");
	
	   	BasicDBObject updateObj = new BasicDBObject();
	   	updateObj.put("$set", documentUpdate);

	   	DBCollection table = m_ddb.getDB().getCollection("fs.files");
	   	table.update(documentWhere, updateObj);
	   	
		return 0;
	
	}

	
	public long put(String fileName, String fullFilePath) throws IOException, DScabiException {
		long time1;
		long time2;
		int n = 0;
		long total = 0;
		
		if (m_firstTime) {
			m_gridFSBucket = GridFSBuckets.create(m_mongodb);
	
	        
	        Date date = new Date();
	        SimpleDateFormat dateFormatGmt = new SimpleDateFormat("yyyy-MMM-dd HH:mm:ss");
	        dateFormatGmt.setTimeZone(TimeZone.getTimeZone("GMT"));
	        String putDateTime = dateFormatGmt.format(date);
	        // To parse from string : Date date2 = dateFormatGmt.parse(putDateTime);
	        // Uses java.time java 8 : ZonedDateTime now = ZonedDateTime.now( ZoneOffset.UTC );	        
	        String millisTime = "" + System.currentTimeMillis();
	        String nanoTime = "" + System.nanoTime();
	        
	        // Create some custom options
			Document doc = new Document();
			doc.append("Type", "File");
			doc.append("ContentType", "File");
			doc.append("PutDateTime", putDateTime);
			doc.append("PutDateTimeInMillis", millisTime);
			doc.append("PutDateTimeInNano", nanoTime);	
			doc.append("PutStatus", "InProgress");
			
			m_options = new GridFSUploadOptions()
	                .chunkSizeBytes(m_chunkSize)
	                .metadata(doc);
	        
	        m_firstTime = false;
		}
		
        // Get the input stream
        time1 = System.currentTimeMillis();
        InputStream fromStream = new FileInputStream(fullFilePath);

        byte data[] = new byte[m_bufferSize];
        GridFSUploadStream uploadStream = m_gridFSBucket.openUploadStream(fileName, m_options);

        while ((n = fromStream.read(data)) > 0) {
            uploadStream.write(data, 0, n);
            total = total + n;
        }
        uploadStream.close();
        fromStream.close();
        
        updateMetaData(uploadStream.getFileId());
        
        time2 = System.currentTimeMillis();
        
        log.debug("put() The fileId of the uploaded file is: " + uploadStream.getFileId().toHexString());
        log.debug("put() Upload time taken : time2 - time1 : " + (time2 - time1));
		
		return total;
	}

	public long put(String fileName, InputStream fromStream) throws IOException, DScabiException {
		long time1;
		long time2;
		int n = 0;
		long total = 0;
		
		if (m_firstTime) {
			m_gridFSBucket = GridFSBuckets.create(m_mongodb);
	
	        // Create some custom options
			m_options = new GridFSUploadOptions()
	                .chunkSizeBytes(m_chunkSize)
	                .metadata(new Document("type", "File"));
			m_firstTime = false;
		}
		
        // Get the input stream
        time1 = System.currentTimeMillis();

        byte data[] = new byte[m_bufferSize];
        GridFSUploadStream uploadStream = m_gridFSBucket.openUploadStream(fileName, m_options);

        while ((n = fromStream.read(data)) > 0) {
            uploadStream.write(data, 0, n);
            total = total + n;
        }
        uploadStream.close();
        fromStream.close();
        
        time2 = System.currentTimeMillis();

        log.debug("put() The fileId of the uploaded file is: " + uploadStream.getFileId().toHexString());
        log.debug("put() Upload time taken : time2 - time1 : " + (time2 - time1));
		
		return total;
	}
	
	public long get(String fileName, String fullFilePath) throws IOException, DScabiException {
		long time1;
		long time2;
		int n = 0;
		long total = 0;
		
		if (m_firstTime) {
			m_gridFSBucket = GridFSBuckets.create(m_mongodb);
	
	        // Create some custom options
			m_options = new GridFSUploadOptions()
	                .chunkSizeBytes(m_chunkSize)
	                .metadata(new Document("type", "File"));
			m_firstTime = false;
		}
		
        time1 = System.currentTimeMillis();
        FileOutputStream toStream = new FileOutputStream(fullFilePath);
        GridFSDownloadByNameOptions downloadOptions = new GridFSDownloadByNameOptions().revision(-1);

        GridFSDownloadStream downloadStream = m_gridFSBucket.openDownloadStreamByName(fileName, downloadOptions);
        //long fileLength = downloadStream.getGridFSFile().getLength();
        byte[] bytesToWriteTo = new byte[m_bufferSize];
        
        while ((n = downloadStream.read(bytesToWriteTo)) > 0) {
        	toStream.write(bytesToWriteTo, 0, n);
        	total = total + n;
        }
        downloadStream.close();
        toStream.close();
        
        time2 = System.currentTimeMillis();
        log.debug("get() Download time taken : time2 - time1 : " + (time2 - time1));
		
		return total;
	}

	public long get(String fileName, OutputStream toStream) throws IOException, DScabiException {
		long time1;
		long time2;
		int n = 0;
		long total = 0;
		
		if (m_firstTime) {
			m_gridFSBucket = GridFSBuckets.create(m_mongodb);
	
	        // Create some custom options
			m_options = new GridFSUploadOptions()
	                .chunkSizeBytes(m_chunkSize)
	                .metadata(new Document("type", "File"));
			m_firstTime = false;
		}
		
        time1 = System.currentTimeMillis();
        GridFSDownloadByNameOptions downloadOptions = new GridFSDownloadByNameOptions().revision(-1);

        GridFSDownloadStream downloadStream = m_gridFSBucket.openDownloadStreamByName(fileName, downloadOptions);
        //long fileLength = downloadStream.getGridFSFile().getLength();
        byte[] bytesToWriteTo = new byte[m_bufferSize];
        
        while ((n = downloadStream.read(bytesToWriteTo)) > 0) {
        	toStream.write(bytesToWriteTo, 0, n);
        	total = total + n;
        }
        downloadStream.close();
        toStream.close();
        
        time2 = System.currentTimeMillis();
        log.debug("get() Download time taken : time2 - time1 : " + (time2 - time1));
		
		return total;
	}

	
}
